{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","timmを使ってCNNモデルを学習させる。\n","optimizer: Adam/AdamW\n","scheduler: OneCycleScheduler/plateau\n","\n","学習:\n","  画像+テーブルデータで学習させる。\n","  テーブルデータを使用しない場合はOTHER_FEATURE_COLUMNSを空配列にする。\n","保存項目:\n","  CSV: フォールド,エポック,loss,ACC,F1,AUC,primary F1,primary F1の閾値\n","  オブジェクト: モデル(model),閾値(threshold),モデル種類(model_type)\n","※ 現在は閾値調整をprimal fscoreに対して行っている。\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:40.784773Z","iopub.status.busy":"2023-02-18T01:35:40.784242Z","iopub.status.idle":"2023-02-18T01:35:40.820758Z","shell.execute_reply":"2023-02-18T01:35:40.819603Z","shell.execute_reply.started":"2023-02-18T01:35:40.784668Z"},"id":"NI_Eh-XDWtlR","trusted":true},"outputs":[],"source":["# データ\n","TRAIN_IMAGE_PATH = 'images'\n","TRAIN_DF_PATH = \"train.csv\"\n","# CV\n","N_SPLITS = 5\n","EPOCHS_PER_FOLD = 1\n","# モデル\n","MODEL_TYPE = 'efficientnet_b2'\n","BATCH_SIZE = 60\n","HIDDEN_SIZE = 64\n","IMG_SIZE_H = 512\n","IMG_SIZE_W = 256\n","# log\n","SAVE_VERSION = 'rsna_first'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# カテゴリ特徴量\n","CATEGORY_COLUMNS = ['category1']\n","# 画像以外のデータフレームから使用する特徴量\n","# OTHER_FEATURE_COLUMNS = ['age'] + CATEGORY_COLUMNS\n","OTHER_FEATURE_COLUMNS = []\n","FILLNA_NUMERIC_COLUMNS = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:40.826678Z","iopub.status.busy":"2023-02-18T01:35:40.824987Z","iopub.status.idle":"2023-02-18T01:35:40.834374Z","shell.execute_reply":"2023-02-18T01:35:40.833176Z","shell.execute_reply.started":"2023-02-18T01:35:40.826635Z"},"id":"OINV-sXWzuSH","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:40.852017Z","iopub.status.busy":"2023-02-18T01:35:40.851169Z","iopub.status.idle":"2023-02-18T01:35:43.293757Z","shell.execute_reply":"2023-02-18T01:35:43.292746Z","shell.execute_reply.started":"2023-02-18T01:35:40.851970Z"},"id":"IhMw_ljXzuSL","trusted":true},"outputs":[],"source":["# 画像のtransform\n","from PIL import Image\n","from torch.utils import data as data\n","from torchvision import transforms as transforms\n","\n","def get_transforms(transform_choises=[0,1,2,3],is_augmentation=False,resize_h=512,resize_w=512):\n","    \"\"\"\n","    transform_choisesはis_augmentation=Trueの時に使用する拡張処理の選択です。\n","    0: ランダムに左右反転\n","    1: ランダムに上下反転\n","    2: ランダムに回転\n","    3: ランダムにリサイズ切り抜き\n","    \"\"\"\n","    TRANS_FORM_LIST = [\n","            # ランダムに左右反転する\n","            transforms.RandomHorizontalFlip(0.5),\n","            # ランダムに上下反転する\n","            transforms.RandomVerticalFlip(0.5),\n","            # ランダム回転\n","            transforms.RandomRotation(degrees=(-5, 5)), \n","            # ランダムにリサイズ切り抜き scaleはU(0.8,1)の倍率で変更される ratioはアスペクト比\n","            transforms.RandomResizedCrop((resize_h, resize_w), scale=(0.8, 1), ratio=(0.45, 0.55)) \n","    ]\n","    if is_augmentation:\n","        transform_pipeline = transforms.Compose(\n","            [\n","               *[TRANS_FORM_LIST[i] for i in transform_choises] +\\\n","                [transforms.ToTensor(),\n","                 transforms.Normalize(mean=0.2179, std=0.0529)],\n","            ]\n","        )\n","    else:\n","        transform_pipeline = transforms.Compose(\n","            [\n","                transforms.RandomHorizontalFlip(0.5),\n","                transforms.Resize((resize_h, resize_w)),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=0.2179, std=0.0529)\n","            ]\n","        )\n","    return transform_pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:43.302059Z","iopub.status.busy":"2023-02-18T01:35:43.298542Z","iopub.status.idle":"2023-02-18T01:35:43.464148Z","shell.execute_reply":"2023-02-18T01:35:43.463243Z","shell.execute_reply.started":"2023-02-18T01:35:43.301979Z"},"id":"hVqNdbBAzuSN","outputId":"955fcc18-a673-4c91-85d6-2d1dfca0e2c3","trusted":true},"outputs":[],"source":["df = pd.read_csv(TRAIN_DF_PATH)\n","df.head()\n","df[FILLNA_NUMERIC_COLUMNS].fillna(df.age.mean(), inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:43.487494Z","iopub.status.busy":"2023-02-18T01:35:43.486966Z","iopub.status.idle":"2023-02-18T01:35:43.657782Z","shell.execute_reply":"2023-02-18T01:35:43.656577Z","shell.execute_reply.started":"2023-02-18T01:35:43.487442Z"},"id":"LKd3pyKRzuSO","outputId":"b8330209-4ae1-4c64-9f58-d91840b1c028","trusted":true},"outputs":[],"source":["# 各行にパスを追加\n","df['my_image_path'] = TRAIN_IMAGE_PATH + '/' + df['tmp'].astype(str) + '.png'\n","df['my_image_path'].head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:43.663556Z","iopub.status.busy":"2023-02-18T01:35:43.663142Z","iopub.status.idle":"2023-02-18T01:35:44.212156Z","shell.execute_reply":"2023-02-18T01:35:44.211055Z","shell.execute_reply.started":"2023-02-18T01:35:43.663521Z"},"id":"T1VGGddczuSP","outputId":"c6083dd2-76b7-47cc-aaef-1ea949e7913f","trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","def label_encoding(df,columns):\n","    df_tmp = df.copy()\n","    for column in CATEGORY_COLUMNS:\n","        df_tmp[column] = LabelEncoder().fit_transform(df[column])\n","    return df_tmp\n","df = label_encoding(df,CATEGORY_COLUMNS)\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:44.227899Z","iopub.status.busy":"2023-02-18T01:35:44.227386Z","iopub.status.idle":"2023-02-18T01:35:47.327015Z","shell.execute_reply":"2023-02-18T01:35:47.325924Z","shell.execute_reply.started":"2023-02-18T01:35:44.227858Z"},"id":"sbImG08OrsYR","outputId":"9ae0ccad-0c8a-4bec-c1f2-b31151aaccde","trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedGroupKFold\n","def do_stratified_group_kfold(df,target_column,group_column):\n","    split = StratifiedGroupKFold(N_SPLITS)\n","    for k, (_, test_idx) in enumerate(split.split(df, df[target_column], groups=df[group_column])):\n","        df.loc[test_idx, 'split'] = k\n","    df.split = df.split.astype(int)\n","    return df\n","do_stratified_group_kfold(df,'cancer','patient_id')\n","display(df.groupby('split')['cancer'].mean())\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:47.329545Z","iopub.status.busy":"2023-02-18T01:35:47.328730Z","iopub.status.idle":"2023-02-18T01:35:47.343563Z","shell.execute_reply":"2023-02-18T01:35:47.342263Z","shell.execute_reply.started":"2023-02-18T01:35:47.329497Z"},"id":"yQ3ZvUc2zuSS","trusted":true},"outputs":[],"source":["# データセット作成\n","import torch\n","from torch.utils.data import Dataset\n","class ImgDataSet(Dataset):\n","    \"\"\"\n","    画像認識の汎用的なデータセットを作成\n","    \"\"\"\n","    def __init__(self,df,target_column,other_columns,transform=None):\n","        self.transform = transform\n","        self.df = df\n","        self.target_column = target_column\n","        self.other_columns = other_columns\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self,index):\n","        try:\n","            img = Image.open(self.df.iloc[index].my_image_path).convert('RGB')\n","        except Exception as ex:\n","            print(self.df.iloc[index].my_image_path,ex)\n","            return None\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        else:\n","            transform_tmp = transforms.ToTensor()\n","            img = transform_tmp(img)\n","\n","        other_features = None\n","        if self.other_columns:\n","            other_features = torch.as_tensor(self.df.iloc[index][self.other_columns])\n","\n","        target_value = None\n","        if self.target_column:\n","            target_value = torch.as_tensor(self.df.iloc[index][self.target_column])\n","\n","        if other_features is not None and target_value is not None:\n","            return img,other_features,target_value\n","        elif other_features is not None:\n","            return img,other_features\n","        elif target_value is not None:\n","            return img,target_value\n","        return img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:47.346565Z","iopub.status.busy":"2023-02-18T01:35:47.345720Z","iopub.status.idle":"2023-02-18T01:35:47.359563Z","shell.execute_reply":"2023-02-18T01:35:47.358244Z","shell.execute_reply.started":"2023-02-18T01:35:47.346478Z"},"id":"wibS16xlzuST","trusted":true},"outputs":[],"source":["from sklearn.utils import compute_class_weight\n","def get_class_weight(df,target_column):\n","    \"\"\"\n","    クラスウェイトを取得\n","    \"\"\"\n","    class_num = np.unique(df[target_column])\n","    class_weights = compute_class_weight(class_weight=\"balanced\",\n","                                         classes=class_num,\n","                                         y=df[target_column])\n","    class_weight_dict = dict(zip(class_num, class_weights))\n","    return class_weight_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:47.364179Z","iopub.status.busy":"2023-02-18T01:35:47.363818Z","iopub.status.idle":"2023-02-18T01:35:47.376539Z","shell.execute_reply":"2023-02-18T01:35:47.375242Z","shell.execute_reply.started":"2023-02-18T01:35:47.364148Z"},"id":"q36evQGHzuST","trusted":true},"outputs":[],"source":["# データローダー作成\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","def make_data_loader(df,target_column,other_columns,transform=None,use_class_weight=False,batch_size = 32):\n","    # データセット作成\n","    dataset = ImgDataSet(df,target_column=target_column,other_columns=other_columns,transform=transform)\n","    # クラスサンプラー作成\n","    sampler = None\n","    if use_class_weight:\n","        class_weight_dict = get_class_weight(df,target_column)\n","        print(f'class weight {class_weight_dict}')\n","        sample_weights = [class_weight_dict[label] for label in df[target_column].values]\n","        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n","        return DataLoader(dataset, batch_size = batch_size, sampler=sampler,num_workers=os.cpu_count(), pin_memory=True)\n","    return DataLoader(dataset, batch_size = batch_size, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:47.391988Z","iopub.status.busy":"2023-02-18T01:35:47.391495Z","iopub.status.idle":"2023-02-18T01:35:48.491228Z","shell.execute_reply":"2023-02-18T01:35:48.489924Z","shell.execute_reply.started":"2023-02-18T01:35:47.391889Z"},"id":"kMeKLi0EzuSU","trusted":true},"outputs":[],"source":["# モデル作成\n","from torch import nn\n","from timm import create_model, list_models\n","class ImgBaseModel(torch.nn.Module):\n","    def __init__(self,num_other_features=0,output_dim=1,hidden_state_features=128,model_name='tf_efficientnet_b4',drop_rate=0.):\n","        \"\"\"\n","        num_other_features: 画像以外の特徴量があればその種類数を記入\n","        \"\"\"\n","        super().__init__()\n","        # num_classes=0でbackboneとして使用する\n","        self.backbone_model = create_model(model_name, pretrained=True,drop_rate=drop_rate,num_classes=0)\n","        self.backbone_features_num = self.backbone_model.num_features\n","        if num_other_features:\n","            self.other_features_network = nn.Sequential(\n","                # 全結合 -> バッチ正規化 -> 活性化関数 -> ドロップアウトの順。\n","                nn.Linear(num_other_features, hidden_state_features),\n","                nn.BatchNorm1d(hidden_state_features),\n","                nn.ReLU(),\n","                nn.Dropout(.2),\n","#                 nn.Linear(hidden_state_features, hidden_state_features),\n","#                 nn.BatchNorm1d(hidden_state_features),\n","#                 nn.ReLU(),\n","#                 nn.Dropout(.2),\n","            )\n","            # 最終層\n","            self.head = nn.Sequential(\n","                nn.Linear(self.backbone_features_num + hidden_state_features, output_dim),\n","            )\n","        else:\n","            self.other_features_network = None\n","            # 最終層\n","            self.head = nn.Sequential(\n","                nn.Linear(self.backbone_features_num, output_dim),\n","            )\n","\n","    def forward(self,X,other_features):\n","        # 画像1枚のみ\n","        if X.dim() == 3:\n","            X = X.unsqueeze(0)\n","        image_network_output = self.backbone_model(X)\n","        # 画像以外の特徴量も使用する場合\n","        if self.other_features_network is not None:\n","            other_features_network_output = self.other_features_network(other_features.float())\n","            head_input = torch.cat((image_network_output, other_features_network_output), dim=1)\n","        else:\n","            head_input = image_network_output\n","        predict_y = self.head(head_input)\n","        return predict_y\n","\n","    def predict(self, X,other_features):\n","        predict_y = self.forward(X,other_features)\n","        return torch.sigmoid(predict_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:48.494038Z","iopub.status.busy":"2023-02-18T01:35:48.493560Z","iopub.status.idle":"2023-02-18T01:35:53.153083Z","shell.execute_reply":"2023-02-18T01:35:53.151986Z","shell.execute_reply.started":"2023-02-18T01:35:48.493993Z"},"id":"3RPeYsQZzuSV","outputId":"81c7a13d-1b9f-4201-cd70-e26ed3aed0d1","trusted":true},"outputs":[],"source":["# デバイスの選択\n","import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = ImgBaseModel(model_name=MODEL_TYPE,hidden_state_features=HIDDEN_SIZE,num_other_features=len(OTHER_FEATURE_COLUMNS))\n","model.to(device)\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:53.155441Z","iopub.status.busy":"2023-02-18T01:35:53.154566Z","iopub.status.idle":"2023-02-18T01:35:53.164873Z","shell.execute_reply":"2023-02-18T01:35:53.163307Z","shell.execute_reply.started":"2023-02-18T01:35:53.155378Z"},"id":"PTucDyIYzuSW","trusted":true},"outputs":[],"source":["# 荷重減衰\n","def add_weight_decay(model, weight_decay=1e-5, skip_list=['bias']):\n","    \"\"\"\n","    荷重減衰を加える\n","    \"\"\"\n","    decay = []\n","    no_decay = []\n","    # named_parametersで各層とそのパラメータを確認する\n","    ## 層: fcはfull connection layer,convはconvolution\n","    ## param: biasとweightがある\n","    for name, param in model.named_parameters():\n","        # 勾配計算が不要ならとばす\n","        if not param.requires_grad:\n","            continue\n","        # スキップリストに入っているならno_decayに入れる(主にbiasを除去)\n","        if len(param.shape) == 1 or np.any([v in name.lower() for v in skip_list]):\n","            no_decay.append(param)\n","        else:\n","            decay.append(param)\n","    return [\n","        {'params': no_decay, 'weight_decay': 0.},\n","        {'params': decay, 'weight_decay': weight_decay}]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:53.167226Z","iopub.status.busy":"2023-02-18T01:35:53.166496Z","iopub.status.idle":"2023-02-18T01:35:53.185812Z","shell.execute_reply":"2023-02-18T01:35:53.184708Z","shell.execute_reply.started":"2023-02-18T01:35:53.167149Z"},"id":"_QpWrSOdzuSX","trusted":true},"outputs":[],"source":["def get_objects_for_train(model,use_weight_decay):\n","    \"\"\"\n","    モデル学習に必要な下記オブジェクトを取得。\n","    ・損失関数\n","    ・スケーラ\n","    ・最適化関数\n","    \"\"\"\n","    # 損失関数\n","    loss_fn = torch.nn.BCEWithLogitsLoss()\n","    # 学習率のスケジューラ\n","    if use_weight_decay:\n","        # betasは勾配の1次と2次モーメントの指数減衰率→ 通常0.9と0.999\n","        # weight decayにはL2正則化のハイパーパラメータを設定\n","        optimizer = torch.optim.AdamW(\n","            add_weight_decay(model,weight_decay=0.025,skip_list=['bias']),\n","            lr=0.001,\n","            betas=(0.9, 0.999),# default\n","            weight_decay=0.025)\n","    else:\n","        optimizer = torch.optim.Adam(model.parameters())\n","    # スケーラ\n","    # 混合精度学習により高速化\n","    scaler = torch.cuda.amp.GradScaler()\n","    return loss_fn,scaler,optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:53.187364Z","iopub.status.busy":"2023-02-18T01:35:53.187028Z","iopub.status.idle":"2023-02-18T01:35:53.197802Z","shell.execute_reply":"2023-02-18T01:35:53.196695Z","shell.execute_reply.started":"2023-02-18T01:35:53.187337Z"},"trusted":true},"outputs":[],"source":["def get_scheduler(is_one_cycle_schedule,optimizer,dataloader,epochs):\n","    if is_one_cycle_schedule:\n","        # onecycle training\n","        ## https://arxiv.org/pdf/1803.09820.pdf\n","        # 基準のlrから、バッチごとに上限のlrまでいけば、次のバッチでは下限のlrまで進める\n","        scheduler =\\\n","        torch.optim.lr_scheduler.OneCycleLR(optimizer,\n","                                            max_lr=0.0008,\n","                                            epochs=epochs,\n","                                            steps_per_epoch=len(dataloader)) # len(dataloader)でバッチ数を取得\n","    else:\n","        # スケジューラの設定、scheduler_patienceで指定したエポック内に前回を超えた精度がでないと、学習率をscheduler_factor倍する。\n","        scheduler =\\\n","        torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                   patience=2,\n","                                                   verbose=True)\n","    return scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:53.200131Z","iopub.status.busy":"2023-02-18T01:35:53.199365Z","iopub.status.idle":"2023-02-18T01:35:53.211960Z","shell.execute_reply":"2023-02-18T01:35:53.210768Z","shell.execute_reply.started":"2023-02-18T01:35:53.200075Z"},"id":"jUzPpysiaAMI","trusted":true},"outputs":[],"source":["def pfbeta(labels, predictions, beta=1.):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp +1e-7)\n","    c_recall = ctp / max(y_true_count, 1)  # avoid / 0\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:53.214345Z","iopub.status.busy":"2023-02-18T01:35:53.213423Z","iopub.status.idle":"2023-02-18T01:35:53.224701Z","shell.execute_reply":"2023-02-18T01:35:53.223553Z","shell.execute_reply.started":"2023-02-18T01:35:53.214294Z"},"id":"MzDr-XDcJIQj","trusted":true},"outputs":[],"source":["def optimal_f1(labels, predictions):\n","    thres = np.linspace(0, 1, 101)\n","    predictions = np.concatenate(predictions)\n","    f1s = [pfbeta(labels, predictions > thr) for thr in thres]\n","    idx = np.argmax(f1s)\n","    return f1s[idx], thres[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:53.227102Z","iopub.status.busy":"2023-02-18T01:35:53.226342Z","iopub.status.idle":"2023-02-18T01:35:54.175989Z","shell.execute_reply":"2023-02-18T01:35:54.174896Z","shell.execute_reply.started":"2023-02-18T01:35:53.227060Z"},"id":"GZXzJiC8zuSX","trusted":true},"outputs":[],"source":["from torchmetrics import Accuracy, F1Score\n","from sklearn.metrics import roc_auc_score\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","accuracy = Accuracy(task=\"binary\").to(device)\n","f1_score = F1Score(task=\"binary\").to(device)\n","\n","def calc_pred_result(y,y_proba):\n","    \"\"\"\n","    性能指標の結果を返します。\n","    \"\"\"\n","    if y_proba.dim() == 0:\n","        y_proba = y_proba.unsqueeze(0)\n","    accuracy_value = accuracy(y_proba, y).item()\n","    f1_score_value = f1_score(y_proba, y).item()\n","    \n","    return accuracy_value,f1_score_value"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:54.177787Z","iopub.status.busy":"2023-02-18T01:35:54.177380Z","iopub.status.idle":"2023-02-18T01:35:54.184016Z","shell.execute_reply":"2023-02-18T01:35:54.182856Z","shell.execute_reply.started":"2023-02-18T01:35:54.177747Z"},"id":"wZYxG5x3zuSY","trusted":true},"outputs":[],"source":["import gc\n","def gc_collect():\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","gc_collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:54.388666Z","iopub.status.busy":"2023-02-18T01:35:54.387821Z","iopub.status.idle":"2023-02-18T01:35:54.400863Z","shell.execute_reply":"2023-02-18T01:35:54.399526Z","shell.execute_reply.started":"2023-02-18T01:35:54.388621Z"},"id":"K9nSWCIczuSY","trusted":true},"outputs":[],"source":["loss_fn,scaler,optimizer =\\\n","    get_objects_for_train(model,use_weight_decay=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:54.404569Z","iopub.status.busy":"2023-02-18T01:35:54.403750Z","iopub.status.idle":"2023-02-18T01:35:54.420235Z","shell.execute_reply":"2023-02-18T01:35:54.418689Z","shell.execute_reply.started":"2023-02-18T01:35:54.404523Z"},"id":"t2l9GQTKzuSZ","trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from sklearn.metrics import roc_auc_score\n","# モデルの学習\n","def train_one_epoch(fold,total_fold,cur_epoch,total_epoch,model,dataloader,loss_fn,scheduler,scaler,optimizer):\n","    \"\"\"\n","    1エポックでの訓練処理\n","    学習\n","     - ロス計算\n","     - 逆伝搬\n","     - 最適化関数の適用\n","     - スケジューラの更新\n","    評価\n","     - ロスの計算\n","     - 最高のスコアが出たらモデルの保存\n","    \"\"\"\n","    # 準備\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model.train()\n","    torch.manual_seed(42)\n","    losses = []\n","    all_labels = []\n","    all_outputs = []\n","\n","    mean_accuracy = 0.\n","    mean_f1_score = 0.\n","    \n","\n","    # 学習\n","    ## 1ループ=1バッチサイズ\n","    loop = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for batch_idx, (X,other_features, y) in loop:\n","        gc_collect()\n","        # 前回計算した勾配を0にする\n","        ## (前回の勾配は主にRNNなどに用いられる)\n","        optimizer.zero_grad(set_to_none=True)\n","        loop.set_description(f\"Fold [{fold+1}/{total_fold}] Epoch [{cur_epoch}/{total_epoch}]\")\n","        X = X.to(device,non_blocking=True)\n","        other_features = other_features.to(device,non_blocking=True)\n","        y = y.to(device,non_blocking=True)\n","        # ampの対象とする\n","        with torch.cuda.amp.autocast():\n","            # 推論\n","            logits = model(X,other_features)\n","            loss = loss_fn(logits, y.unsqueeze(1).float())\n","        losses.append(loss.item())\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scheduler.step()\n","        scaler.update()\n","\n","        # 精度評価\n","        y_proba = torch.sigmoid(logits).squeeze()\n","        accuracy_value,f1_score_value = calc_pred_result(y,y_proba)\n","        mean_accuracy += accuracy_value\n","        mean_f1_score += f1_score_value\n","\n","        outputs = list(torch.sigmoid(logits).detach().cpu().numpy())\n","        labels = list(y.detach().cpu().numpy())\n","\n","        all_outputs.extend(outputs)\n","        all_labels.extend(labels)\n","        auc = roc_auc_score(all_labels,all_outputs)\n","\n","        pfscore,thresh=optimal_f1(all_labels,all_outputs)\n","        loop.set_postfix(loss=loss.item(), acc=accuracy_value, f1=f1_score_value,auc=auc,pfscore=pfscore,thresh=thresh)\n","\n","        del loss, logits, X, other_features, y\n","\n","    mean_loss = sum(losses) / len(losses)\n","    mean_accuracy /= len(losses)\n","    mean_f1_score /= len(losses)\n","    return [mean_loss, mean_accuracy, mean_f1_score,auc,pfscore,thresh]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:54.428176Z","iopub.status.busy":"2023-02-18T01:35:54.427332Z","iopub.status.idle":"2023-02-18T01:35:54.443208Z","shell.execute_reply":"2023-02-18T01:35:54.441956Z","shell.execute_reply.started":"2023-02-18T01:35:54.428143Z"},"id":"7l3kKmOIzuSZ","trusted":true},"outputs":[],"source":["def valid_one_epoch(fold,total_fold,cur_epoch,total_epoch,model, dataloader, loss_fn):\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model.eval()\n","    losses = []\n","    mean_accuracy = 0.\n","    mean_f1_score = 0.\n","    all_labels = []\n","    all_outputs = []\n","    \n","    with torch.inference_mode():\n","        loop = tqdm(enumerate(dataloader), total=len(dataloader))\n","        for batch_idx, (X, other_features, y) in loop:\n","            gc_collect()\n","            loop.set_description(f\"Fold {fold+1}/{total_fold} Epoch [{cur_epoch}/{total_epoch}]\")\n","\n","            X = X.to(device,non_blocking=True)\n","            other_features = other_features.to(device,non_blocking=True)\n","            y = y.to(device,non_blocking=True)\n","\n","            logits = model(X,other_features)\n","            loss = loss_fn(logits, y.unsqueeze(1).float())\n","            losses.append(loss.item())\n","\n","            y_proba = torch.sigmoid(logits).squeeze()\n","            accuracy_value,f1_score_value = calc_pred_result(y,y_proba)\n","            mean_accuracy += accuracy_value\n","            mean_f1_score += f1_score_value\n","\n","            outputs = list(torch.sigmoid(logits).detach().cpu().numpy())\n","            labels = list(y.detach().cpu().numpy())\n","            all_outputs.extend(outputs)\n","            all_labels.extend(labels)\n","            auc = roc_auc_score(all_labels,all_outputs)\n","\n","            pfscore,thresh=optimal_f1(all_labels,all_outputs)\n","\n","            loop.set_postfix(loss=loss.item(), acc=accuracy_value, f1=f1_score_value,auc=auc,pfscore=pfscore,thresh=thresh)\n","            del loss, logits, X, other_features, y\n","            \n","        mean_loss = sum(losses) / len(losses)\n","        mean_accuracy /= len(losses)\n","        mean_f1_score /= len(losses)\n","        \n","    return [mean_loss, mean_accuracy, mean_f1_score,auc,pfscore,thresh]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:54.446287Z","iopub.status.busy":"2023-02-18T01:35:54.445560Z","iopub.status.idle":"2023-02-18T01:35:54.458073Z","shell.execute_reply":"2023-02-18T01:35:54.457055Z","shell.execute_reply.started":"2023-02-18T01:35:54.446236Z"},"id":"veCt1E4PzuSa","trusted":true},"outputs":[],"source":["import csv\n","# csvに精度などのlogを残していく\n","cols = [\"fold\",\"epoch\", \"training_loss\", \"training_acc\", \"training_f1\",'training_auc','training_pfscore','training_thresh',\n","        \"validation_loss\",\"validation_acc\", \"validation_f1\",'validation_auc','validation_pfscore','validation_thresh']\n","\n","if not os.path.isdir(SAVE_VERSION):\n","    os.makedirs(SAVE_VERSION)\n","\n","with open(f\"{SAVE_VERSION}/log.csv\", \"w\") as f:\n","    csv_writer = csv.writer(f)\n","    csv_writer.writerow(cols)\n","    \n","def writeCSVLog(vals):\n","    with open(f\"{SAVE_VERSION}/log.csv\", \"a\") as f:\n","        csv_writer = csv.writer(f)\n","        csv_writer.writerow(vals)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-18T01:35:54.460457Z","iopub.status.busy":"2023-02-18T01:35:54.459969Z","iopub.status.idle":"2023-02-18T01:38:19.170550Z","shell.execute_reply":"2023-02-18T01:38:19.168466Z","shell.execute_reply.started":"2023-02-18T01:35:54.460393Z"},"id":"sY0YcEw_zuSa","outputId":"626e63b9-19c3-4c4d-c29d-b9740e0de7d7","trusted":true},"outputs":[],"source":["def train_valid(model,df,loss_fn,optimizer,scaler,batch_size=16,total_epoch_per_fold=3):\n","    for fold in range(N_SPLITS):\n","        gc_collect()\n","        train_dataloader =\\\n","        make_data_loader(df.query('split != @fold'),target_column='cancer',other_columns=OTHER_FEATURE_COLUMNS,transform=get_transforms(transform_choises=[0,1,2,3],is_augmentation=True,resize_h=IMG_SIZE_H,resize_w=IMG_SIZE_W),use_class_weight=True,batch_size = BATCH_SIZE)\n","        valid_dataloader =\\\n","        make_data_loader(df.query('split == @fold'),target_column='cancer',other_columns=OTHER_FEATURE_COLUMNS,transform=get_transforms(transform_choises=[0,1,2,3],is_augmentation=True,resize_h=IMG_SIZE_H,resize_w=IMG_SIZE_W),use_class_weight=True,batch_size = BATCH_SIZE)\n","        # データローダのサイズに合わせてスケジューラを作成\n","        scheduler =\\\n","        get_scheduler(is_one_cycle_schedule=True,optimizer=optimizer,dataloader=train_dataloader,epochs=total_epoch_per_fold)\n","        # 学習実施\n","        for epoch in range(1, total_epoch_per_fold+1):\n","            train_vals = train_one_epoch(fold,N_SPLITS,epoch,total_epoch_per_fold,model,train_dataloader,loss_fn,scheduler,scaler,optimizer)\n","            valid_vals = valid_one_epoch(fold,N_SPLITS,epoch,total_epoch_per_fold,model,valid_dataloader, loss_fn)\n","            torch.save({'model': model.state_dict(), 'threshold': valid_vals[-1], 'model_type': MODEL_TYPE}, f\"fold{fold}_epoch{epoch}_{MODEL_TYPE}_{HIDDEN_SIZE}\")\n","            vals = [fold,epoch, ] + train_vals + valid_vals\n","            writeCSVLog(vals)\n","\n","train_valid(\n","    model,\n","    df,\n","    loss_fn,\n","    optimizer,\n","    scaler,\n","    batch_size=BATCH_SIZE,\n","    total_epoch_per_fold=EPOCHS_PER_FOLD)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"f855e809d28f537ea7daf8d381b4126b23f3b52263e3ca74f4231481873cb795"}}},"nbformat":4,"nbformat_minor":4}
